import os
import sys
import traceback
from datetime import datetime
from datetime import timedelta
import asyncio
import json

from loguru import logger
from stats_collector import StatsCollector
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–æ–¥—É–ª–∏
from data_manager import DataManager, get_msk_date_range
from text_preprocessing import TextPreprocessor
from lm_studio_client import LMStudioClient
from telegram_sender import TelegramSender
from token_estimator import TokenEstimator
from db_manager import DBManager
from post import Post

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger.remove()
logger.add(sys.stderr, level="INFO")
logs_dir = os.path.join(os.getcwd(), "logs")
os.makedirs(logs_dir, exist_ok=True)
logger.add(
    os.path.join(logs_dir, "insightflow_{time}.log"),
    rotation="10 MB",
    retention="21 days",
    encoding="utf-8",
    enqueue=True,
    backtrace=False,
    diagnose=False,
    level="INFO",
)


class InsightFlow:
    def __init__(self):
        self.data_manager = DataManager()
        self.text_preprocessor = TextPreprocessor(
            similarity_threshold=0.65,
            min_content_length=100,
            max_tokens=50000
        )
        self.lm_client = LMStudioClient()
        self.telegram_sender = TelegramSender()
        self.token_estimator = TokenEstimator()

        try:
            self.db_manager = DBManager()
            self.db_manager.create_tables()
            logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            self.db_manager = None

        logger.info("DataManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–≤–∫–ª—é—á–∞—è RSS –∏ –ú–µ–¥–∏–∞–ª–æ–≥–∏—é)")

    async def run_daily_job(self):
        try:
            from zoneinfo import ZoneInfo
            now = datetime.now(ZoneInfo("Europe/Moscow"))
            yesterday_09 = (now - timedelta(days=1)).replace(hour=9, minute=1, second=0, microsecond=0)
            today_09 = now.replace(hour=9, minute=0, second=0, microsecond=0)

            logger.info(f"üìÜ –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç: {yesterday_09} ‚Üí {today_09}")

            if not await self.lm_client.test_connection():
                logger.error("LM Studio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –æ—Ç–º–µ–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑")
                await self.telegram_sender.send_message("‚ö†Ô∏è LM Studio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–º–µ–Ω–µ–Ω.")
                return

            # 1. –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø–æ—Å—Ç—ã –∏–∑ –ë–î
            db_posts = self.db_manager.get_relevant_posts(
                since=yesterday_09,
                until=today_09,
                limit=1000,
            )

            initial = [
                {
                    "post_id": p.post_id,
                    "title": p.title,
                    "content": p.content,
                    "url": p.url,
                    "score": p.relevance_score or 0.0,
                }
                for p in db_posts
                if (p.relevance_score or 0.0) >= 0.7 and p.content
            ]

            logger.info(f"üîé –ù–∞–π–¥–µ–Ω–æ {len(initial)} –ø–æ—Å—Ç–æ–≤ —Å score ‚â• 0.7")

            # 2. –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            unique = self.text_preprocessor.remove_duplicates(initial)
            logger.info(f"üßπ –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(unique)}")

            # 3. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            rechecked = await self.lm_client.recheck_relevance_strict(unique)
            logger.info(f"‚úÖ –ü–æ–≤—Ç–æ—Ä–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö: {len(rechecked)}")

            # 4. –û—Ç–±–æ—Ä –¥–æ 7 –ª—É—á—à–∏—Ö
            top_posts = await self.lm_client.select_top_posts(rechecked, top_n=7)

            if not top_posts:
                logger.warning("–ù–µ—Ç –ø–æ—Å—Ç–æ–≤ –¥–ª—è Telegram")
                await self.telegram_sender.send_message("üìä –ó–∞ —Å—É—Ç–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π.")
                return

            # 5. –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
            summaries = await self.lm_client.analyze_and_summarize(top_posts)

            if summaries:
                # –§–∏–Ω–∞–ª—å–Ω—ã–π –¥–µ–¥—É–ø —Å—é–∂–µ—Ç–æ–≤ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ Telegram
                try:
                    deduped = self.text_preprocessor.dedupe_summaries(
                        summaries, title_threshold=0.85, content_threshold=0.70
                    )
                    logger.info(f"–§–∏–Ω–∞–ª—å–Ω—ã–π –¥–µ–¥—É–ø: {len(summaries)} ‚Üí {len(deduped)}")
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–µ–¥—É–ø–∞, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å: {e}")
                    deduped = summaries

                mapping = self.db_manager.create_post_mapping_from_db(db_posts)
                await self.telegram_sender.send_analysis(deduped, mapping)
                self.db_manager.update_post_summaries(summaries)
                # –û–±–Ω–æ–≤–∏—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ (–¥–µ–Ω—å/–Ω–µ–¥–µ–ª—è/–º–µ—Å—è—Ü) –≤ –º–µ—Å—è—á–Ω—ã–π JSON
                try:
                    from zoneinfo import ZoneInfo
                    day = datetime.now(ZoneInfo("Europe/Moscow")).date()
                    sc = StatsCollector()
                    sc.reset()
                    sc.scan_logs_for_date(logs_dir, day)
                    sc.flush_monthly(logs_dir, day)
                except Exception as se:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–¥–∫—É –º–µ—Ç—Ä–∏–∫: {se}")
                logger.info("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")

            else:
                logger.warning("–ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è")
                await self.telegram_sender.send_message("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –ø—É–±–ª–∏–∫–∞—Ü–∏–π.")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ run_daily_job: {e}")
            logger.error(traceback.format_exc())
            await self.telegram_sender.send_message(f"‚ùå –û—à–∏–±–∫–∞ –≤ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ:\n{str(e)[:200]}")

    async def run_hourly_job(self):
        from zoneinfo import ZoneInfo
        now = datetime.now(ZoneInfo("Europe/Moscow"))
        date_from = now - timedelta(hours=24)
        date_to = now - timedelta(minutes=1)

        logger.info("[‚è∞] Hourly job window: {} ‚Üí {}", date_from, date_to)

        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ UTC –¥–ª—è API
        utc_from = date_from.astimezone(ZoneInfo("UTC"))
        utc_to = date_to.astimezone(ZoneInfo("UTC"))

        posts = await self.data_manager.fetch_posts(
            date_from=utc_from,
            date_to=utc_to,
        )

        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(posts)} –ø–æ—Å—Ç–æ–≤ –∑–∞ –æ–∫–Ω–æ {date_from} ‚Äì {date_to}")

        existing_urls = set(self.db_manager.get_all_posts_urls())
        new_posts = [p for p in posts if p.url not in existing_urls]
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(new_posts)} –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤")

        inserted = self.db_manager.save_posts(new_posts)
        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î: {inserted} –ø–æ—Å—Ç–æ–≤")

        if inserted == 0:
            logger.info("–ù–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ –Ω–µ—Ç, –Ω–æ –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç–∞—Ä—ã—Ö —Å relevance=NULL –∏ –±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")


        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö relevance=NULL
        from relevance_checker import RelevanceChecker
        checker = RelevanceChecker()
        await checker.process_unchecked_posts()

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ —Å score >= 0.7
        from content_classifier import classify_relevant_posts_task
        await classify_relevant_posts_task()

        logger.success("‚úÖ Hourly job –∑–∞–≤–µ—Ä—à—ë–Ω")


# –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫
async def run_insight_flow():
    try:
        service = InsightFlow()
        await service.run_daily_job()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ InsightFlow: {e}")
        logger.error(traceback.format_exc())


if __name__ == "__main__":
    asyncio.run(run_insight_flow())
